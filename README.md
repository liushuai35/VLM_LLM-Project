# VLM_LLM-Project

An in-depth paper reading & reproduction hub for Vision-Language Models (VLMs) and Large-Language Models (LLMs)

---

## 🎯 Mission
- Track and dissect the latest top-tier conferences (ICML, NeurIPS, CVPR, ICCV, ACL, ...) in real time.
- Deliver **line-by-line explanations**, **derivations**, and **reproducible code** for every highlighted VLM paper.

---

## 📚 Papers Decoded & Reproduced (continuously updated)
| Paper | Venue | Reading | Reproduction |
|---|---|---|---|
| DeepSeek-VL | 2024 | ✅ Available | — |
| DeepSeek-MoE | 2024 | ✅ Available | — |
| DeepSeek-V2 | 2024 | ✅ Available | — |
| DeepSeek-V3 | 2024 | ✅ Available | — |
| DeepSeek-R1 | 2025 | ✅ Available | — |
| Intern-VL3 | 2025 | ✅ Available | — |
| Intern-VL3.5 | 2025 | ✅ Available | — |
| Qwen2.5-VL | 2025 | ✅ Available | — |
| Qwen2-VL | 2024 | ✅ Available | — |
| GME | 2025 | ✅ Available | — |
| Glm4.5-V | 2025 | ✅ Available | — |
| llama-nemotron | 2025 |  | — |
| minicpm-v | 2025 |  | — |
| TRPO | 2017 |  | — |
| PPO | 2017 | ✅ Available | — |
| GRPO | 2024 | ✅ Available | — |
| GSPO | 2024 | ✅ Available | — |
| ... | ... | ... | ... |

Want to jump the queue? Open an [Issue](https://github.com/YOUR_NAME/VLM_Proj/issues) and we'll add it to the TODO list!

---

## 🤝 How to Contribute
1. **Fix bugs**: incorrect equations / code → PR welcome.
2. **Submit new readings**: follow the `template.ipynb` format and PR.
3. **Join discussions**: questions about experiments → open an Issue.

---

## 📬 Contact
- Email: shuai_liu@tju.edu.cn
- Blog: [https://blog.csdn.net/a284365](https://blog.csdn.net/a284365) (long-form posts synchronized)

If this repo helps your research, please ⭐ Star & Watch to get notified of the latest decoding updates!
