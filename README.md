# VLM_Proj

An in-depth paper reading & reproduction hub for Vision-Language Models (VLMs)

---

## ğŸ¯ Mission
- Track and dissect the latest top-tier conferences (ICML, NeurIPS, CVPR, ICCV, ACL, ...) in real time.
- Deliver **line-by-line explanations**, **derivations**, and **reproducible code** for every highlighted VLM paper.

---

## ğŸ“š Papers Decoded & Reproduced (continuously updated)
| Paper | Venue | Reading | Reproduction |
|---|---|---|---|
| Qwen2.5-VL Technical Report | 2025 | âœ… Available | â€” |
| ... | ... | ... | ... |

Want to jump the queue? Open an [Issue](https://github.com/YOUR_NAME/VLM_Proj/issues) and we'll add it to the TODO list!

---

## ğŸ¤ How to Contribute
1. **Fix bugs**: incorrect equations / code â†’ PR welcome.
2. **Submit new readings**: follow the `template.ipynb` format and PR.
3. **Join discussions**: questions about experiments â†’ open an Issue.

---

## ğŸ“¬ Contact
- Email: shuai_liu@tju.edu.cn
- Blog: [https://blog.csdn.net/a284365](https://blog.csdn.net/a284365) (long-form posts synchronized)

If this repo helps your research, please â­ Star & Watch to get notified of the latest decoding updates!
